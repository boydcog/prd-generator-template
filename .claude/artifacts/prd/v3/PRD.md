# Maththera PRD v3 -- AI 기반 난산증 인지 훈련 시스템

**프로젝트명**: Maththera
**버전**: 3.0
**문서 유형**: 제품 요구사항 문서 (PRD)
**생성일**: 2026-02-13
**생성 방식**: 에이전트 팀 통합 (biz, marketing, research, tech, pm, synth)
**추가 소스**: W/C 이중 태그 문제 뱅크, 데이터 기반 오답 교정 알고리즘

---

## 목차

1. [개요 (Executive Summary)](#1-개요-executive-summary)
2. [문제 정의](#2-문제-정의)
3. [목표 / 비목표](#3-목표--비목표)
4. [대상 사용자 / 페르소나](#4-대상-사용자--페르소나)
5. [기능 요구사항](#5-기능-요구사항)
6. [비기능 요구사항](#6-비기능-요구사항)
7. [UX 노트](#7-ux-노트)
8. [기술 노트](#8-기술-노트)
9. [GTM 전략](#9-gtm-전략)
10. [리스크](#10-리스크)
11. [마일스톤](#11-마일스톤)
12. [미해결 질문](#12-미해결-질문)

---

## 1. 개요 (Executive Summary)

### 1.1 한줄 요약

**Maththera는 난산증 아동의 오답을 인지 원인으로 진단하고, W/C 이중 태그 기반 적응형 알고리즘으로 맞춤 훈련을 자동 처방하는 AI 수학 훈련 시스템이다.**

### 1.2 핵심 가치 제안

기존 수학 학습 도구는 "맞았다/틀렸다"만 판별한다. Maththera는 **왜 틀렸는지**를 뇌과학 기반 C-S-E 인지 모델로 진단하고, **어떤 훈련이 필요한지**를 자동으로 처방한다. [CLM-003]

```
[문제정의 13,981개] -> [오답원인 85개] -> [훈련모듈 30+2개]
```

이 수렴 파이프라인은 1:1 전문 치료사 수준의 개인화된 개입을 AI로 구현한다. [CLM-002]

### 1.3 v3의 핵심 진화

v3에서는 두 가지 핵심 소스가 새롭게 통합되었다.

**W/C 이중 태그 시스템**: 6개 Working Memory 가중치(W1~W6)로 산출된 W_총점과 15개 교과과정(C) 단원의 이중축으로, 모든 문제를 W 레벨 1~23과 C 레벨 1~15로 정밀 분류한다. [SYNTH-NEW-001]

**적응형 오답 교정 알고리즘**: 수감각 진단 질문 기반으로 경로 A(W 하향, 작업기억 최적화)와 경로 B(C 하향, 개념적 후퇴)를 결정하는 데이터 기반 교정 루프를 제공한다. [SYNTH-NEW-002]

### 1.4 시스템 전체 구조도

```
+------------------------------------------------------------------+
|                    Maththera System                                |
|                                                                    |
|  [문제 뱅크]          [진단 엔진]          [훈련 엔진]              |
|  15,050개 문제        C-S-E 3축 분석       30+2개 모듈              |
|  W 레벨 1~23         85개 오답원인         5대 유형                  |
|  C 레벨 1~15         7대 인지 카테고리      Perception/Concept/     |
|  6개 W 가중치        Rule 70% + AI 30%     Strategy/Drill/         |
|                                            Intervention            |
|                                                                    |
|  [적응형 알고리즘]                                                  |
|  경로 A: W 하향 (작업기억 최적화)                                   |
|  경로 B: C 하향 (개념적 후퇴)                                       |
|  훈련 루프: 심각한 오답 -> 논리적 오답 -> 정답+느림 -> 정답+빠름    |
+------------------------------------------------------------------+
```

---

## 2. 문제 정의

### 2.1 난산증이란

난산증(Dyscalculia)은 지능과 교육 기회가 충분함에도 불구하고, 수적 정보를 처리하는 뇌 회로의 발달적 결함으로 인해 수학 학습에 심각한 어려움을 겪는 상태이다. 이는 후두정엽(수 표상)과 전전두엽(집행 제어) 사이의 신경학적 연결성 문제에 기인한다. [CLM-001]

전 세계 학령기 아동의 **3~6%**에 해당하며, 난독증과 유사한 유병률을 보이지만 사회적 인지도와 전문 개입 도구는 현저히 부족하다. [CLM-001]

### 2.2 기존 접근의 한계

| 기존 접근 | 한계 | Maththera의 대안 |
|-----------|------|-------------------|
| 문제 반복 풀이 | "왜 틀렸는가"를 설명 불가 | C-S-E 3축 인지 진단 [CLM-003] |
| 난이도 단순 조절 | 인지적 원인 분석 없이 양적 조절 | W/C 이중 태그 정밀 조절 [SYNTH-NEW-001] |
| 범용 적응형 학습 | 난산증 특화 진단 체계 부재 | 85개 오답원인 MECE 분류 [CLM-004] |
| 오프라인 치료 | 접근성/비용/전문가 수 제한 | 24/7 AI 기반 자동화 [MKT-CLM-005] |
| 정오답 이분법 | 정답이어도 비효율적 전략 미감지 | 전략 불일치 감지 + RT 분석 [RES-CLM-009] |

### 2.3 핵심 인사이트

1. **수감각 회복이 수학 능력 향상의 관건이다**: C-S-E 인지 모델에 따르면 개념(C), 전략(S), 집행(E) 3축 중 어느 축에 결함이 있는지를 정밀 식별하면 맞춤형 훈련 경로를 설계할 수 있다. [RES-CLM-001]

2. **정오답만으로는 진단이 불충분하다**: 정답이어도 전략 불일치(예: MAKE10 전략이 필요한 문제에서 COUNTING으로 풀이)가 감지되면 유창성 훈련이 처방되어야 한다. [RES-CLM-009]

3. **작업기억 부하가 핵심 병목이다**: 난산증 아동은 작업기억(E축) 임계치가 낮아, 문제 난이도가 인지 레벨을 초과하면 충동적 반응이나 중간 단계 망각이 발생한다. [RES-CLM-007]

4. **적응형 교정은 W 하향과 C 하향의 이중 경로가 필요하다**: 전략은 알지만 계산에서 막히는 아동(경로 A)과 개념 자체를 모르는 아동(경로 B)에게 서로 다른 교정 경로를 적용해야 한다. [SYNTH-NEW-002]

---

## 3. 목표 / 비목표

### 3.1 목표 (Goals)

| 목표 | 측정 지표 | 목표값 | 근거 |
|------|----------|--------|------|
| 정밀 인지 진단 | AI 진단 vs 전문가 진단 일치율 | 85%+ | [CLM-005] |
| 전략 전환 유도 | 훈련 전후 strategy_tag 전환율 | 60%+ | [CLM-006] |
| 적응형 문제 출제 | W/C 레벨 기반 문제 적합도 | 90%+ | [SYNTH-NEW-001] |
| 수학 불안 감소 | MARS 점수 변화 | 15%+ 감소 | [CLM-013] |
| 학습 지속성 | 세션 완료율 / D7 재방문율 | 70%+ / 40%+ | [BIZ-KPI] |

### 3.2 비목표 (Non-Goals)

| 비목표 | 이유 |
|--------|------|
| 곱셈/나눗셈 지원 | MVP는 덧셈/뺄셈 수감각에 집중 [PM-CLM-SCOPE-001] |
| 세자리수 이상 연산 | 인지 복잡도 과다, 초기 검증 불가 |
| DTx(디지털치료기기) 인허가 | Phase 3에서 임상 데이터 축적 후 추진 [BIZ-RSK-002] |
| 다국어 지원 | 한국어 전용 (글로벌 확장은 Phase 3) |
| AI(LLM) 전면 활용 | MVP는 Rule-based 70~90% + AI 보조 [TECH-003] |
| 오프라인 모드 | 네트워크 연결 필수 (MVP) |

---

## 4. 대상 사용자 / 페르소나

### 4.1 1차 사용자: 난산증 아동 (만 5~10세)

| 세그먼트 | 설명 | 추정 규모 (한국) |
|---------|------|----------------|
| 진단된 난산증 아동 | 전문기관 진단 완료 | 약 12~24만명 |
| 수학 학습부진 아동 | 미진단이나 심각한 어려움 | 약 40~60만명 |
| 수감각 강화 필요 아동 | 예방적 훈련 대상 | 약 80~120만명 |

### 4.2 페르소나

#### 페르소나 A: 민준 (7세, 초등 1학년)

- **상황**: 한자리수 덧셈에서 항상 손가락으로 하나씩 세기(counting). 8+7 같은 문제에서 12초 이상 소요.
- **진단 예상**: S 축 결함 (S1 전부세기에 고착, S3 MAKE10 전략 미숙)
- **적응형 경로**: 경로 A (W 하향) -- 전략은 이해하지만 실행에서 작업기억 부하 초과
- **Maththera 처방**: T12(10짝찾기) -> T15(짝꿍수 암기) -> T17(가르기모으기 반복)

#### 페르소나 B: 서연 (8세, 초등 2학년)

- **상황**: 23+4=6으로 계산. 자릿값의 공간적 의미를 이해하지 못함.
- **진단 예상**: C 축 결함 (C4 자릿값 개념 부재) + 공간처리 도메인
- **적응형 경로**: 경로 B (C 하향) -- 자릿값 개념 자체 결손, C 레벨을 8에서 5로 하향
- **Maththera 처방**: T26(자릿값이해) -> T18(자릿값분해)

#### 페르소나 C: 지호 (6세, 취학 전)

- **상황**: 문제를 0.8초 만에 아무 답이나 누름. 무작위 오답.
- **진단 예상**: ATTENTION 도메인 (충동적 반응)
- **적응형 경로**: 비인지적 개입 우선
- **Maththera 처방**: T30(주의력환기) -> T19(단계별 힌트)

### 4.3 구매 의사결정자

| 구매자 | 핵심 니즈 | 채널 | 가치 메시지 |
|--------|----------|------|------------|
| 학부모 | 자녀의 수학 불안 해소 | B2C (앱) | "왜 틀리는지 알 수 있어요" [MKT-CLM-001] |
| 특수교육 교사 | 개별화 교육 도구 | B2B (학교) | "전문 진단 자동화" [MKT-CLM-009] |
| 소아정신과 의사 | 과학적 근거 기반 도구 | B2B (병원) | "C-S-E 인지 모델 기반" [MKT-CLM-002] |
| 학습치료 센터 | 비용 효율적 콘텐츠 | B2B (센터) | "1:1 치료사 대비 1/10 비용" |

---

## 5. 기능 요구사항

### 5.1 핵심 파이프라인

#### FR-001: W/C 이중 태그 기반 문제 출제 엔진

**설명**: 15,050개 문제 뱅크에서 W 레벨(1~23)과 C 레벨(1~15)의 이중축을 기반으로 적응형 문제를 선택한다. [SYNTH-NEW-001]

**W(Working Memory) 가중치 체계**:

| 가중치 | 의미 | 범위 | 예시 |
|--------|------|------|------|
| W1_연산 | 연산 유형 | 0 / 1.5 | 덧셈(0), 뺄셈(1.5) |
| W2_자릿수 | 자릿수 | 0~4 | 한자리(0), 두자리(3), 두자리x두자리(4) |
| W3_숫자크기 | 크기 | 0~1 | 6이상(+0.5), 양쪽 큰 수(+1.0) |
| W4_복잡성 | 절차 | 0 / 3 | 받아올림/받아내림 시 +3.0 |
| W5_특수수 | 보정 | -1.5~0 | 같은 수(-0.5), 10배수(-1.0) |
| W6_표현 | 형식 | 0 / 0.5 | 가로셈(0.5), 세로셈(0) |

**W_총점** = W1+W2+W3+W4+W5+W6 (범위: 0 ~ 약 9.5)
**W 레벨**: 1~23 (0.5 단위 구간화)

**C(교과과정) 단원 체계**:

| C | 조건 | 예시 |
|---|------|------|
| 1 | 1~9 수끼리 덧셈 | 3+4 |
| 2 | 1~9 수끼리 뺄셈 | 7-3 |
| 3 | 0을 더하는 문제 | 5+0 |
| 4 | 0을 빼는 문제 | 8-0 |
| 5 | 더해서 10이 되는 문제 | 8+2 |
| 6 | 10에서 빼는 문제 | 10-3 |
| 7 | (몇)+(몇)=(십몇) | 8+6 |
| 8 | 받아올림 없는 두자리수 덧셈 | 23+14 |
| 9 | 받아내림 없는 두자리수 뺄셈 | 37-12 |
| 10 | 일의자리 받아올림 (두자리+한자리) | 28+5 |
| 11 | 일의자리 받아올림 (두자리+두자리) | 27+36 |
| 12 | 십의자리 받아올림 (두자리+두자리) | 45+62 |
| 13 | 받아내림 (두자리-한자리) | 32-7 |
| 14 | 받아내림 (몇십-몇십몇) | 50-23 |
| 15 | 받아내림 (두자리-두자리) | 43-18 |

**수용 기준**:
- AC-001-1: W 레벨과 C 레벨의 이중축 필터링으로 문제가 선택된다
- AC-001-2: 6개 W 가중치(W1~W6)의 산출이 정확하다
- AC-001-3: 동일 세션 내 문제 중복이 발생하지 않는다
- AC-001-4: 문제별 strategy_tag, carry_borrow, concept_tags가 정확히 부여된다

#### FR-002: C-S-E 기반 인지 진단 엔진

**설명**: 아동의 응답(답, RT, 변경 횟수)을 수집하고, C-S-E 인지 모델에 따라 오답 원인을 진단한다. [RES-CLM-001] [RES-CLM-002]

**C-S-E 3축 체계**:

| 축 | 세부 | 대응 관계 | 진단 시사점 |
|----|------|----------|------------|
| C(개념) | C1 기수성 ~ C6 가역성 | C-S 1:1 대응 | C 문제: 시각적 수 표상 훈련 |
| S(전략) | S1 전부세기 ~ S7 유형분류 | S는 대응 C에 의존 | S 문제: 메타인지 발문 훈련 |
| E(집행) | E1 정보유지량, E2 절차적 단계, E3 수의 물리적 크기 | 48단계 난이도 체계 | E 문제: 단계적 연산 훈련 |

**진단 파이프라인**:

```
입력(오답, RT, 관찰 태그)
    |
    +---> [C 평가기] --- 개념 결함 여부 --+
    |                                      |
    +---> [S 평가기] --- 전략 불일치 여부 --+---> 종합 진단 ---> error_tag (85개 중 1)
    |                                      |                   + confidence (0.65~0.98)
    +---> [E 평가기] --- 인지 부하 수준 ---+                   + training_id 매핑
```

**수용 기준**:
- AC-002-1: C, S, E 각 축이 독립적으로 평가되어 합산된다 [TECH-002]
- AC-002-2: 85개 오답 원인 태그 중 하나가 확정되고 confidence가 산출된다
- AC-002-3: 확정된 error_tag에서 training_id로 자동 매핑된다
- AC-002-4: Rule-based 엔진이 70~90%를 처리한다 [TECH-003] [PM-CLM-FR-005]

#### FR-003: 적응형 오답 교정 알고리즘 (The Adaptive Loop)

**설명**: 아동의 오답 유형에 따라 W 하향(경로 A) 또는 C 하향(경로 B)으로 자동 교정 경로를 결정한다. [SYNTH-NEW-002]

**경로 결정 로직**:

```
아이가 문제를 틀림
    |
    v
[수감각 진단 질문]
"8이 10이 되려면 몇이 필요해?"
    |
    +--- 답할 수 있음 ---> 경로 A (W 하향)
    |                      "전략은 알지만 계산에서 막힘"
    |                      동일 C 레벨, W_총점 낮은 문제 검색
    |                      예: 8+6 (W:4.5) -> 9+2 (W:2.5)
    |
    +--- 답 못 함 -------> 경로 B (C 하향)
                           "가르는 이유, 보수 자체를 모름"
                           C 레벨 1~2단계 하향 검색
                           예: 8+6 (C:7) -> 8+□=10 (C:5)
```

**훈련 루프 설계**:

| 아이의 반응 | 다음 문제 결정 로직 | 훈련 목적 |
|------------|-------------------|----------|
| 심각한 오답 (8+6=1) | C 레벨 -2 & W_총점 < 1.0 | 수 관계 기초 복구 |
| 논리적 오답 (가르기 실수) | C 유지 & W_총점 1.5+ 낮은 문제 | 작업기억 부하 경감 |
| 정답이지만 느림 (5초+) | C, W 동일 수준 다른 숫자 | 수 관계 자동화 |
| 정답 및 빠른 반응 | W_총점 +1.0 또는 C +1 | 도전적 과제 부여 |

**Downscaling 방법**:
1. 시각적 보조: 10 프레임(계란판) 투입
2. 단계 분리: "계산하지 말고 결정만 해봐"
3. 숫자 크기 축소: 8+7 -> 8+3
4. 세로셈 전환: 가로셈(W6:+0.5) -> 세로셈(W6:0)

**Upscaling 조건**:
1. 시각 힌트 제거
2. 추상화 (가르기 선 없이)
3. 수치 확장: 8+7 -> 18+7 -> 28+7

**수용 기준**:
- AC-003-1: 수감각 진단 질문이 오답 발생 후 자동 제시된다
- AC-003-2: 경로 A(W 하향)에서 동일 C 레벨 내 W_총점이 낮은 문제가 검색된다
- AC-003-3: 경로 B(C 하향)에서 C 레벨이 1~2단계 하향된 문제가 검색된다
- AC-003-4: 훈련 루프의 4단계 반응 유형에 따른 분기가 동작한다

#### FR-004: 개념 태그 트리거 룰 엔진

**설명**: 문제 유형별로 C1~C6 태그의 활성화 조건을 Rule-based로 적용한다. AI 에이전트의 자의적 해석을 배제하기 위해 정교한 트리거 룰을 사용한다. [CLM-005] [RES-CLM-004]

**하위 개념 우선 스캔 (Bottom-up Selection)**: 기초 문항(예: 3+0)에서는 하위 개념 태그(C1, C2)만 활성화하여 과진단을 방지한다. [TECH-010]

**수용 기준**:
- AC-004-1: 한자리수+한자리수 문제에서 C1~C5 트리거가 정확히 동작한다
- AC-004-2: 한자리수-한자리수 문제에서 C1~C6 트리거가 정확히 동작한다
- AC-004-3: 기초 문항에서는 하위 개념 태그만 스캔된다

#### FR-005: 전략 태그 / 관찰 태그 분리 운영

**설명**: 문제 설계 관점의 전략 태그(6종)와 아동 행동 관점의 관찰 태그(15종)를 분리 관리한다. 두 태그의 불일치(mismatch)가 바로 진단의 트리거이다. [CLM-015] [TECH-008]

**전략 태그 6종** (문제의 요구조건, 정적):
- STR_FACT_RETRIEVAL (기본 사실 인출)
- STR_COUNTING (세기 전략)
- STR_MAKE10 (10 만들기)
- STR_PLACEVALUE (자릿값)
- STR_DECOMPOSE_COMPOSE (분해/합성)
- STR_ESTIMATION_CHECK (추정/검증)

**관찰 태그 15종** (아동의 실제 행동, 동적):
- 예: OBS_OVERRELIANCE_COUNTING, OBS_PLACEVALUE_CONFUSION, OBS_VERY_SLOW_RT, OBS_VERY_FAST_RT 등

**수용 기준**:
- AC-005-1: 각 문제는 반드시 하나의 strategy_tag를 갖는다
- AC-005-2: observation_tag는 아동/세션마다 독립적으로 생성된다
- AC-005-3: 전략 태그와 관찰 태그의 불일치(전략 미숙)를 감지한다 [RES-CLM-009]

### 5.2 유스케이스 진단 시나리오

#### UC1: 10의 보수 전략 미숙 (전략 불일치)

```
문제: 8+7=?  |  아동 응답: 15 (정답)  |  RT: 12초 (느림)
행동: OBS_OVERRELIANCE_COUNTING (하나씩 세기 의심)
전략 불일치: 문제는 STR_MAKE10 요구, 아동은 COUNTING 사용
진단: 전략 미숙 (S3 결함)
처방: T12(10짝찾기) -> T17(가르기모으기)
적응형: W 유지, 다른 숫자로 자동화 훈련
```
[RES-CLM-009] [MKT-CLM-006]

#### UC2: 자릿값 혼동 (공간처리 결함)

```
문제: 23+4=?  |  아동 응답: 6 (오답)
오답 패턴: 2+4=6 (자릿값 무시, 십의 자리 탈락)
진단: SPATIAL_PLACEVALUE_CONFUSION (공간처리 도메인)
처방: T26(자릿값이해)
적응형: 경로 B -- C 레벨 하향 (C:8 -> C:5)
```
[RES-CLM-006] [MKT-CLM-007]

#### UC3: 충동적 반응 (비인지적 요인)

```
문제: 5+3=?  |  아동 응답: 2 (오답)  |  RT: 0.8초 (극도로 빠름)
행동: 무작위 버튼 누름
진단: ATTENTION_L0_IMPULSE
처방: T30(주의력환기) -> T19(단계별 힌트)
적응형: 비인지적 개입 우선, 수학 문제 일시 중단
```
[TECH-012]

#### UC4: 오답 원인 중복 (Probe 기반 감별 진단)

```
문제: 24+18=?  |  아동 응답: 32
가설 A: 공간 지각 오류 (자릿수 정렬 실패)
가설 B: 절차 수행 오류 (받아올림 미실행)
Probe 출제: 20+15=? (받아올림 제거, 변인 통제)
 -> Probe 정답: 가설 A 기각, 가설 B 확정 -> T24(보정 화살표)
 -> Probe 오답: 가설 A 확정 -> T26(자릿값이해)
```
[RES-CLM-006]

### 5.3 훈련 모듈

#### 우선순위 훈련 모듈 (MVP Phase 1)

| 순위 | ID | 명칭 | 유형 | 연결 오답원인 수 | 설명 |
|------|----|------|------|-----------------|------|
| 1 | T12 | 10짝찾기 | Strategy | 8 | 10의 보수 관계 직관화 |
| 2 | T15 | 짝꿍수 암기 | Drill | 6 | 보수 쌍 자동화 |
| 3 | T04 | 순간 포착 1~5 | Perception | 5 | 수양감 시각화 |
| 4 | T22 | 10격자 채우기 | Concept | 4 | 10 단위 구조화 |
| 5 | T08 | 수직선 점프 | Concept | 4 | 수직선 위 연산 시각화 |
| 6 | T18 | 자릿값 분해 | Strategy | 3 | 십의 자리/일의 자리 분리 |
| 7 | T11 | 더하기 카운터 | Drill | 3 | 이어세기 자동화 |
| 8 | T24 | 보정 화살표 | Strategy | 3 | 받아올림/내림 시각화 |
| 9 | T06 | 크기 비교 | Perception | 2 | 수량 크기 직관 |
| 10 | T27 | 배수 패턴 | Drill | 2 | 배수 관계 자동화 |

**긴급 개입 모듈** (항상 활성):
- **T30**: 주의력 환기 -- 충동적 반응 감지 시 즉시 개입
- **T19**: 단계별 힌트 표시 -- 인지 부하 과다 시 개입

#### 훈련 완료 기준

| 조건 | 기준 | 후속 |
|------|------|------|
| 통과 (pass) | 연속 5문제 정답 또는 정답률 90%+ | 상위 레벨 문제로 이동 |
| 미달 (fail) | 5회 연속 오답 | 하위 훈련 단계로 분기 |
| 선행 미충족 | prereq_training 미완료 | 선행 훈련 먼저 제시 |

### 5.4 RT(반응 시간) 분석

**설명**: 아동의 반응 시간을 분석하여 진단 및 적응형 알고리즘에 활용한다. [TECH-006]

**적응형 알고리즘 연동**: RT는 적응형 교정 루프의 핵심 신호이다. [SYNTH-NEW-002]
- 정답이지만 느림 (5초+): 동일 W/C 수준의 다른 숫자로 자동화 훈련
- 정답이고 빠름: W_총점 +1.0 또는 C +1로 도전 과제 부여
- RT < 1초 + 오답: 충동적 반응 감지 -> T30 즉시 개입

**수용 기준**:
- AC-RT-1: Category별 baseline_rt_mean, baseline_rt_sd가 참조된다
- AC-RT-2: z-score > +2.0 시 OBS_VERY_SLOW_RT, z-score < -2.0 시 OBS_VERY_FAST_RT 생성
- AC-RT-3: 연속 5문제 RT 평균이 세션 평균 대비 +50% 이상이면 휴식 제안

### 5.5 4개 데이터베이스 구조

| DB | 레코드 수 | 핵심 필드 | 역할 |
|----|----------|----------|------|
| 문제정의 | 13,981 (태깅: 15,050) | problem_id, W1~W6, W_총점, W_레벨, C_레벨, strategy_tag | 문제 속성 정의 [SYNTH-NEW-001] |
| 오답원인 | 85 | error_tag, category(7대), description | 인지 결함 분류 [CLM-004] |
| 훈련매핑 | 85 | error_tag -> training_id, repeat_count, pass_criterion | 진단-훈련 연결 |
| 훈련모듈 | 30+2 | training_id, type(5대), content_config | 훈련 콘텐츠 [CLM-006] |

**데이터 무결성 원칙**: 4개 DB 간 참조 무결성을 자동 검증하는 CI 테스트를 포함해야 한다. [CLM-011] [PM-CLM-NFR-003]

---

## 6. 비기능 요구사항

### 6.1 성능

| 지표 | 목표값 | 근거 |
|------|--------|------|
| RT 측정 정밀도 | < 10ms 오차 | 밀리초 단위 RT가 진단 핵심 데이터 [TECH-006] |
| 문제 출제 응답 시간 | < 200ms (p95) | 아동 집중력 유지 |
| 진단 파이프라인 지연 | < 500ms | 오답 후 즉시 피드백/Probe 제공 [TECH-007] |
| W/C 레벨 기반 문제 검색 | < 50ms (p99) | 복합 인덱스 RDBMS 쿼리 |
| 동시 접속 사용자 | 1,000명 (초기) | 교육기관 단위 배포 |

### 6.2 보안 및 개인정보보호

| 항목 | 요구사항 | 구현 방안 |
|------|---------|----------|
| 아동 개인정보 | COPPA/PIPA 준수 | 익명 UUID, 최소 수집, 학부모 동의 필수 [TECH-RISK-003] |
| 데이터 암호화 | 전송 중/저장 시 | TLS 1.3 (전송), AES-256 (저장) |
| 인증 | 학부모 계정 인증 | OAuth 2.0 + JWT, RBAC |
| 데이터 격리 | 사용자별 세션 데이터 격리 | API 인가 필수 |

### 6.3 데이터 무결성

- 4개 DB(문제정의, 오답원인, 훈련매핑, 훈련모듈) 간 참조 무결성 자동 검증 [PM-CLM-NFR-003]
- 85개 error_tag가 7대 카테고리에 MECE하게 분류됨을 검증 [CLM-004]
- W1~W6 가중치 산출의 정확성 자동 검증 [SYNTH-NEW-001]
- W_총점과 W 레벨 매핑의 일관성 검증

### 6.4 확장성

| 항목 | 현재 | 확장 목표 | 전략 |
|------|------|----------|------|
| 문제 뱅크 | 15,050개 | 50,000+ | category 기반 수평 확장 |
| 오답 원인 | 85개 | 200+ | error_tag 네임스페이스 확장 |
| 훈련 모듈 | 30+2개 | 100+ | training_type별 플러그인 구조 |
| C 단원 | 15개 | 25+ (곱셈/나눗셈 포함) | C 레벨 확장 |
| W 레벨 | 1~23 | 1~40+ | W_총점 상한 확장 |

---

## 7. UX 노트

### 7.1 보이스 톤 가이드

**페르소나**: 따뜻하고 격려하는 친구 같은 튜터 (수달 캐릭터) [CLM-013]

**핵심 원칙**: "아이가 '틀려도 괜찮다'는 느낌으로 다시 시도하게 만들기"

| 규칙 | 상세 | 예시 |
|------|------|------|
| 반말 사용 | 존댓말 금지, 부드럽게 | "잘했어!" (O), "잘하셨습니다" (X) |
| 3문장 이내 | 피드백 당 최대 3문장 | |
| 문장당 10자 이내 | 인지 부하 최소화 [MKT-CLM-011] | "한 번 더 해볼까?" |
| 힌트 1개만 | 한 번에 하나의 정보 | |
| 비난/재촉/비교 금지 | 부정적 감정 유발 차단 | "왜 몰라?" (X), "틀렸어!" (X) |

**상황별 피드백 템플릿**:

| 상황 | 톤 | 예시 |
|------|-----|------|
| 정답 | 짧은 칭찬 | "좋아!", "멋져!", "딩동!" |
| 오답 | 격려 + 단서 | "괜찮아! 다시 해볼까?" |
| 실수 (경미) | 부드러운 안내 | "잠깐, 한 번 더 볼까?" |
| 무응답 | 기다림 + 격려 | "천천히 해도 돼!" |

### 7.2 적응형 교정의 UX 원칙 [SYNTH-NEW-002]

**Downscaling 시 UX**:
- 난이도가 낮아지는 것을 아동이 인식하지 못하게 자연스럽게 전환
- 시각적 보조(10 프레임) 투입 시 "도구를 써볼까?"로 제안
- 절대 비난하지 않음: "쉬운 문제부터"가 아닌 "다른 문제 해볼까?"

**결정권 존중**:
- "어디서 가를까?" 반복 질문으로 아동의 주도성 유지
- "계산하지 말고 결정만 해봐" -- 단계 분리로 부하 경감

### 7.3 시각적 메타포

| 메타포 | 용도 | 구현 |
|--------|------|------|
| 기찻길 | 수직선 기반 연산 시각화 | SVG/Canvas 기반 인터랙티브 |
| 블록 (파란/빨간) | 수량 표현 | 파란색 블록 + 빨간색 블록 |
| 금색 바 (10개) | 10 단위 구조화 | 10격자 채우기 연동 |
| 10 프레임 (계란판) | Downscaling 시각 보조 | 2x5 격자 [SYNTH-NEW-002] |

### 7.4 접근성

| 항목 | 요구사항 |
|------|---------|
| 터치 타겟 | 최소 48px (태블릿 우선) |
| 색상 | 색맹 대응 패턴 병행, 고대비 모드 |
| 정보 밀도 | 한 화면에 하나의 정보만 제시 |
| 피드백 | 음성(TTS) + 시각 동시 제공 |

---

## 8. 기술 노트

### 8.1 시스템 아키텍처

```
+-------------------+      +------------------------+      +------------------+
|  Client (Web/App) |<---->|  API Gateway (Backend) |<---->|  Data Store      |
|  - 문제 렌더링      |      |  - Session Manager     |      |  - Problem Bank  |
|  - RT 측정 (로컬)   |      |  - Rule Engine         |      |  - Error Tags    |
|  - 피드백 표시       |      |  - Diagnosis Pipeline  |      |  - Training Map  |
|  - 경량 룰 평가기    |      |  - Adaptive Selector   |      |  - Session Log   |
|  (충동 감지)         |      |  - Adaptive Loop (NEW) |      |  - User Profile  |
+-------------------+      |  - Cogassist Agent     |      |  - W/C Index     |
                            +------------------------+      +------------------+
```

### 8.2 핵심 기술 의사결정

| 결정 | 선택 | 근거 |
|------|------|------|
| 진단 엔진 | 하이브리드 (Rule 70% + AI 30%) | "자의적 해석 배제" 요구 [TECH-003] |
| 적응형 알고리즘 | W/C 이중축 기반 경로 A/B | W_총점과 C 레벨 데이터 활용 [SYNTH-NEW-001] |
| 피드백 시스템 | 템플릿 기반 (MVP) | LLM 금지어 리스크 회피 [TECH-009] |
| RT 측정 | 클라이언트 로컬 (performance.now()) | 네트워크 지연 배제 [TECH-006] |
| 충동 감지 | 클라이언트 경량 룰 평가기 | 서버 왕복 없이 즉시 감지 [TECH-012] |
| 데이터베이스 | PostgreSQL | 복합 인덱스, JSONB 태그 배열 |
| 태그 체계 | 스키마 버전 관리 | C5a/C5b 분리 등 예정 [TECH-011] |

### 8.3 추천 기술 스택

| 계층 | 기술 | 근거 |
|------|------|------|
| 프론트엔드 | React (Next.js) + TypeScript | 인터랙티브 훈련 UI |
| 시각화 | Canvas API / PixiJS | 블록/기찻길 메타포 애니메이션 |
| 백엔드 | Node.js (Fastify) 또는 Python (FastAPI) | 룰 엔진 + API |
| 룰 엔진 | 커스텀 (TypeScript/Python) | 트리거 룰 특수성 |
| DB | PostgreSQL | 복합 인덱스, W/C 다차원 조회 |
| 캐시 | Redis | 세션 상태, RT 임계값 |
| AI | Claude API (2차 분석 전용) | Probe 해석 한정 |
| TTS | 네이버 클로바 / Google Cloud TTS | 한국어 아동 음성 |
| 인프라 | AWS (ECS/RDS) 또는 GCP | 관리형 서비스 |

### 8.4 데이터 모델 (주요 엔티티)

```
[Problem Bank]
  problem_id, category, operand_a, operand_b, answer,
  W1~W6, W_총점, W_레벨,           -- NEW: W 가중치 체계
  C_레벨,                           -- NEW: C 교과과정 단원
  L_level, C_level,                 -- 기존 L/C 난이도
  strategy_tag, carry_borrow, concept_tags[]

[Session Response]
  response_id, session_id, problem_id,
  user_answer, is_correct, rt_ms,
  observation_tags[], timestamp

[Error Diagnosis]
  diagnosis_id, response_id,
  error_tag, confidence,
  diagnosed_by ('rule_engine' | 'cogassist_agent'),
  adaptive_path ('A_W_down' | 'B_C_down' | null),   -- NEW
  probe_triggered

[Training Mapping]
  error_tag, training_id, repeat_count,
  pass_criterion, prereq_training_id

[Adaptive State]                     -- NEW: 적응형 상태 추적
  user_id, current_W_level, current_C_level,
  adaptive_path, downscale_count, upscale_count,
  last_diagnostic_question_result
```

---

## 9. GTM 전략

### 9.1 포지셔닝

**핵심 선언문**: "Maththera는 난산증 아동의 수 인지 결함을 과학적으로 진단하고, AI 기반 개인화 훈련으로 수감각을 회복시키는 인지 훈련 프로그램이다." [MKT-CLM-001]

**카테고리 전략**:
- 1차: 난산증 전문 인지 훈련 프로그램 (Blue Ocean)
- 2차: 수감각 기초 역량 강화 플랫폼 (TAM 확장)
- 장기: AI 기반 학습 장애 진단/치료 통합 플랫폼

> **주의**: '치료'라는 표현은 의료법 저촉 가능성. 마케팅에서는 '인지 훈련', '수감각 개선', '맞춤 지원'으로 대체한다. [MKT-RSK-001]

### 9.2 메시징 필러

| 필러 | 학부모 메시지 | 전문가 메시지 | 근거 |
|------|-------------|-------------|------|
| 과학적 진단 | "왜 틀리는지 이제 정확히 알 수 있어요" | "C-S-E 인지 모델 기반 자동 진단" | [MKT-CLM-002] |
| 개인화 처방 | "같은 오답도 원인이 다릅니다" | "W/C 이중 태그 + 적응형 알고리즘" | [SYNTH-NEW-001] |
| 아이 중심 경험 | "혼내지 않는 AI 친구" | "인지 부하 최소화 UX 원칙" | [MKT-CLM-004] |
| 전문가 자동화 | "전문 센터 없이 집에서" | "Bottom-up 정밀 진단, Probe 감별 진단" | [MKT-CLM-012] |

### 9.3 수익 모델

**Phase 1-2: 에듀테크 (SaaS)**

| 모델 | 가격 | 대상 |
|------|------|------|
| 무료 체험 | 0원 / 7~14일 | 전체 |
| 베이직 (B2C) | 월 19,900~29,900원 | 학부모 |
| 프리미엄 (B2C) | 월 39,900원 | 학부모 (상세 진단 + 상담) |
| 기관 라이선스 (B2B) | 아동당 월 15,000~25,000원 | 학교/치료센터/병원 |

**Phase 3: DTx 전환 시**

| 모델 | 가격 | 대상 |
|------|------|------|
| 처방형 DTx | 세션당 50,000원+ | 건강보험 적용 |
| 프리미엄 B2B | 기관당 연 1,200만원+ | 대형 병원/센터 |

### 9.4 매출 전망 (보수적)

| 구분 | Year 1 | Year 2 | Year 3 |
|------|--------|--------|--------|
| B2C 유료 사용자 | 500 | 3,000 | 10,000 |
| B2B 계약 기관 | 5 | 30 | 100 |
| **연간 총매출** | **약 1.7억원** | **약 12.5억원** | **약 42억원** |
| 월간 손익분기 | - | Phase 2 후반 | 달성 |

### 9.5 시장 환경

- 글로벌 에듀테크: 2025년 1,891억 달러 -> 2034년 5,887억 달러 [CLM-009]
- AI 교육: 2025년 70.5억 달러 -> 2034년 1,123억 달러 [CLM-009]
- 한국 DTx: 2024년 11월 기준 80건 임상 승인, 난산증 특화 부재 [CLM-012]

### 9.6 경쟁 분석

| 제품 | 주요 특징 | Maththera 대비 한계 |
|------|----------|-------------------|
| Dybuster Calcularis (스위스) | ITS 기반 적응형, 30~45% 개선율 | MECE 오답분류 부재, 한국어 미지원 |
| DreamBox (미국) | 적응형 수학 플랫폼 | 난산증 비특화, 인지 진단 부재 |
| Khan Academy (미국) | 무료 수학 교육 | 진단 기능 부재, 일방향 |
| Todo Math (한국) | 유아/초등 수학 게임 | 난산증 비특화, 진단 부재 |

**Maththera 핵심 차별점**:

| 축 | Maththera | 경쟁사 |
|----|-----------|-------|
| 오답원인 분류 | 85개 MECE (7대 인지 카테고리) | 단순 정오답 |
| 인지 모델 | C-S-E 프레임워크 (뇌과학) | 행동주의 반복 |
| 난이도 체계 | W/C 이중 태그 + L/C 2축 | 단일 축 |
| 적응형 교정 | 경로 A/B 자동 결정 [SYNTH-NEW-002] | 단순 난이도 조절 |
| 진단-개입 연결 | 4DB 파이프라인 (설명가능 AI) | 블랙박스 |
| 전략 분리 | strategy_tag vs observation_tag | 미분리 |

---

## 10. 리스크

### 10.1 종합 리스크 매트릭스

| ID | 리스크 | 심각도 | 가능성 | 카테고리 | 완화 전략 |
|----|--------|--------|--------|----------|----------|
| RSK-001 | RT 기준값 실측 데이터 부재 | **높음** | 중간 | 진단 정확도 | 파일럿 50~100명 데이터 수집. 초기 절대 임계값(1초 미만=충동, 15초 이상=어려움) 사용 후 z-score 전환 [BIZ-RSK-001] [TECH-RISK-001] |
| RSK-002 | DTx 인허가 12~24개월 소요 + 규제 불확실성 | **높음** | 높음 | 규제 | 에듀테크로 우선 출시 후 임상 데이터 축적, DTx 병행 추진 [BIZ-RSK-002] |
| RSK-003 | 난산증 인지도 부족 -> 고객 획득 난항 | **높음** | 높음 | 마케팅 | '수감각이 약한 아이'로 진입, KOL 네트워크 + 학부모 인식 캠페인 [MKT-RSK-002] |
| RSK-004 | 의료법 저촉 표현 사용 | **높음** | 중간 | 법률 | '인지 훈련 프로그램'으로 통일, 법률 검토 필수 [MKT-RSK-001] |
| RSK-005 | 아동 개인정보보호 규정 미준수 | **높음** | 낮음 | 법률 | COPPA/PIPA 기반 익명 UUID, 학부모 동의 필수 [MKT-RSK-005] [TECH-RISK-003] |
| RSK-006 | AI 비결정론적 진단으로 일관성 저하 | **높음** | 낮음 | 기술 | Rule 1차 + AI 2차 하이브리드, confidence 임계값 미만시 전문가 검토 큐 [TECH-RISK-002] |
| RSK-007 | 피드백 톤 가이드 위반 (아동 심리적 부정 경험) | **높음** | 낮음 | UX | 템플릿 기반 + 금지어 필터, LLM 생성 배제 (MVP) [TECH-RISK-005] |
| RSK-008 | C-S-E 태그 정합성 오류 | **높음** | 중간 | 진단 정확도 | 독립 검증 세트, Inter-rater reliability 측정 [PM-RISK-002] |
| RSK-009 | 콘텐츠 확장(곱셈/나눗셈) 시 매트릭스 재설계 | **중간** | 중간 | 확장성 | 모듈형 아키텍처, 스키마 버전 관리 [TECH-RISK-004] |
| RSK-010 | 경쟁사 유사 기능 도입 | **중간** | 중간 | 경쟁 | C-S-E 모델 + 4DB 파이프라인 + W/C 이중 태그 특허 선제 확보 [BIZ-RSK-005] |
| RSK-011 | 아동 사용자 이탈률 | **중간** | 높음 | UX | 보이스 톤 엄격 적용, 세션 문제 수 제한, 휴식 제안 [PM-RISK-003] |
| RSK-012 | T1-level-criteria.csv 데이터 손상 | **높음** | 확정 | 데이터 | Google Sheets 원본 재다운로드, 인덱싱 파이프라인에 유효성 검증 추가 [RES-RSK-001] |

### 10.2 리스크 완화 우선순위

```
[즉시 조치 필요]
  RSK-012: 레벨 판정 기준 데이터 복구
  RSK-001: 파일럿 테스트 계획 수립

[MVP 전 완료]
  RSK-005: 개인정보보호 정책 수립
  RSK-007: 피드백 템플릿 + 금지어 필터 구현
  RSK-008: C-S-E 태그 검증 세트 구성

[운영 중 모니터링]
  RSK-003: 인지도 캠페인 효과 추적
  RSK-006: AI 진단 confidence 분포 모니터링
  RSK-011: 세션 완료율, D7 재방문율 추적
```

---

## 11. 마일스톤

### Phase 1: 코어 파이프라인 (Week 1~4)

**목표**: W/C 이중 태그 기반 문제 출제 + Rule-based 진단 + 적응형 교정 루프의 기본 파이프라인 완성

| 주차 | 마일스톤 | 산출물 |
|------|----------|--------|
| W1 | 데이터 모델링 + 4DB 구축 + W/C 인덱스 | 문제정의 CSV(W1~W6 포함), 오답원인/훈련매핑/훈련모듈 테이블 |
| W2 | W/C 이중 태그 기반 문제 출제 엔진 | 적응형 출제 API, W/C 레벨 필터링 로직 |
| W3 | 개념 태그 트리거 룰 엔진 + RT 수집 | 트리거 룰 엔진 v1, 응답 로그 수집기 |
| W4 | Rule-based 오답 진단 + 적응형 교정 루프 | 진단 엔진 v1, 경로 A/B 결정 로직, 훈련 매핑 |

### Phase 2: 훈련 모듈 구현 (Week 5~8)

**목표**: 우선순위 훈련 모듈 10+2개 구현 + 아동 사용자 여정 완성

| 주차 | 마일스톤 | 산출물 |
|------|----------|--------|
| W5 | T12(10짝찾기), T15(짝꿍수 암기) | 핵심 수감각 훈련 2종 |
| W6 | T04(순간포착), T22(10격자채우기), T08(수직선점프) | 개념/지각 훈련 3종 |
| W7 | T18(자릿값분해), T11(더하기카운터), T24(보정화살표) | 전략 훈련 3종 |
| W8 | T06(크기비교), T27(배수패턴), T30(주의력환기), T19(단계별힌트) + 통합 | 나머지 훈련 + Downscaling/Upscaling UX + 통합 테스트 |

### Phase 3: 검증 및 고도화 (Week 9~12)

**목표**: 임상 파일럿 + W/C 데이터 기반 알고리즘 보정 + 태그 고도화

| 주차 | 마일스톤 | 산출물 |
|------|----------|--------|
| W9 | 소규모 파일럿 (n=50) + RT baseline 수집 | 파일럿 데이터, 경로 A/B 분포 분석 |
| W10 | 파일럿 결과 분석 + Rule 테이블 보정 + W 가중치 보정 | 보정된 진단 테이블, W 가중치 검증 리포트 |
| W11 | C5a/C5b 분리, C1-Zero 서브태그 구현 | 고도화된 태그 체계 |
| W12 | 두자리수 연산 확장 + B2C 퍼블릭 런칭 준비 | 확장된 문제 범위, 런칭 패키지 |

### Phase 4: 성장 (Month 4~18)

| 기간 | 목표 | 핵심 KPI |
|------|------|---------|
| M4~6 | B2C 퍼블릭 런칭, B2B 파일럿 | MAU 1,000+, B2B 계약 5건+ |
| M7~12 | 성장 가속, AI 보조 도입 | MAU 5,000+, 유료전환 15%+ |
| M13~18 | DTx 임상 개시, 해외 진출 검토 | DTx 임상시험 개시 |

---

## 12. 미해결 질문

### 높은 우선순위

| ID | 질문 | 담당 | 관련 근거 |
|----|------|------|----------|
| OQ-001 | **파일럿 테스트 대상 기관/일정 확정**: 최소 50명 대상 파일럿이 MVP 전 필요하다. 대상 기관(병원/학교/치료센터)과 일정이 확정되지 않았다. | PO / 사업팀 | [BIZ-OQ-001] |
| OQ-002 | **RT z-score 기준선 데이터**: 반응 시간 평가를 위한 연령/학년별 정규분포 데이터가 미확보. 자체 파일럿으로 수집할지 외부 연구 데이터를 차용할지 결정 필요. | Data Science | [RES-OQ-005] [TECH-OQ-001] |
| OQ-003 | **DTx vs 에듀테크 우선 출시 전략**: 규제 비용(12~24개월, 자금)과 시장 검증 속도를 고려한 전략 확정 필요. | 경영진 | [BIZ-OQ-002] |
| OQ-004 | **B2B vs B2C 초기 GTM 우선순위**: 각 채널의 CAC/LTV 비교 분석이 필요하다. | 사업팀 | [BIZ-OQ-004] [MKT-OQ-004] |
| OQ-005 | **AI 진단 confidence 값의 임상적 유효성**: 전문가 진단과의 일치도를 파일럿에서 측정해야 한다. | 임상 자문 | [BIZ-OQ-005] |
| OQ-006 | **MVP 연산 범위 최종 확정**: 한자리수 덧셈/뺄셈으로 한정할지, 두자리수+한자리수까지 포함할지. | PO | [PM-OQ-001] |
| OQ-007 | **적응형 경로 A/B 진단 질문의 자동화 가능성**: 수감각 진단 질문("8이 10이 되려면?")을 시스템이 자동 제시할 수 있는지, 치료사/교사 개입이 필요한지. | 기술팀 / 임상 자문 | [SYNTH-NEW-002] |
| OQ-008 | **T1-level-criteria.csv 원본 복구**: Google 로그인 HTML로 손상된 레벨 판정 기준 데이터의 원본 복구가 시급하다. | 도메인 전문가 | [RES-RSK-001] |

### 중간 우선순위

| ID | 질문 | 담당 |
|----|------|------|
| OQ-009 | Probe 문제(변인 통제) 로직의 임상적 유효성 및 MVP 포함 여부 | 임상 자문 |
| OQ-010 | C7(등가성) 태그 추가 여부 (현재 보류) | 도메인 전문가 |
| OQ-011 | 학부모/교사 대시보드 MVP 범위 (기본 리포트 vs 훈련 이력 추적) | PO |
| OQ-012 | Cogassist Agent의 AI 의존 범위 -- 룰 엔진 커버리지 비율 | 기술팀 |
| OQ-013 | 뺄셈 특화 전략 태그 체계의 완성도 확인 | 도메인 전문가 |
| OQ-014 | 15,050개 레벨태깅 문제와 13,981개 문제정의 간 수량 차이(1,069개) 정합성 | 도메인 전문가 |
| OQ-015 | W 가중치(W1~W6)의 임상적 타당성 -- 가중치 값이 실제 작업기억 부하를 반영하는지 파일럿 검증 필요 | Data Science / 임상 자문 |
| OQ-016 | 글로벌 확장 시 문제정의 로컬라이제이션 범위/비용 산정 | 사업팀 |

### 낮은 우선순위

| ID | 질문 | 담당 |
|----|------|------|
| OQ-017 | C7 등가성 태그 도입 시점 및 기술적 영향 범위 | 기술팀 |
| OQ-018 | 오프라인 환경 지원 필요 여부 (학교/치료실) | 기술팀 |
| OQ-019 | 시각 메타포(기찻길-블록) 사용성 테스트 | UX |
| OQ-020 | 경쟁사(Calcularis) 대비 효과 크기 입증 실험 설계 | 임상 자문 |

---

## 부록

### A. 에이전트별 기여 요약

| 에이전트 | 주요 기여 영역 | 핵심 Claims |
|---------|--------------|------------|
| **biz** | 시장 기회, 수익 모델, 경쟁 분석, KPI | CLM-001~015 (15건) |
| **marketing** | 포지셔닝, 메시징, GTM 채널, 가격 전략 | CLM-001~015 (15건) |
| **research** | C-S-E 모델 검증, 증거 맵, 가정 목록 | CLM-001~012 (12건) |
| **tech** | 아키텍처, 기술 의사결정, 비기능 요구사항 | TECH-001~012 (12건) |
| **pm** | 스코프, 기능 요구사항, 마일스톤, 수용 기준 | CLM-SCOPE/FR/NFR/MS (16건) |
| **synth** | W/C 이중 태그, 적응형 알고리즘 통합, 충돌 해결 | SYNTH-NEW-001~002 |

### B. 증거 소스 인덱스

| 소스 | 유형 | 주요 내용 |
|------|------|----------|
| dyscalculia-cse-cognitive-model | 이론 모델 | C-S-E 3축 인지 프레임워크 |
| maththera-master-matrix | 시스템 아키텍처 | 4DB 파이프라인, 85개 오답원인, 30개 훈련모듈 |
| maththera-concept-tag | 시스템 설계 | 개념 태그 트리거 룰, Bottom-up 스캔 |
| maththera-matrix-usecase | 검증 시나리오 | 4개 유스케이스 진단-훈련 시나리오 |
| maththera-level-tag | 데이터셋 | 15,050개 문제 레벨 태깅, W1~W6 가중치 |
| prd-template-voice-tone-guide | UX 가이드 | AI 피드백 보이스 톤 규칙 |
| prd-template-example | 템플릿 | PRD 문서 구조 참고 |
| **adaptive-algorithm** (NEW) | 알고리즘 | 데이터 기반 오답 교정 경로 A/B, 훈련 루프 |
| **wc-problem-bank** (NEW) | 데이터셋 | W/C 이중 태그, 6개 W 가중치, 15개 C 단원 |

### C. 용어 정의

| 용어 | 정의 |
|------|------|
| C-S-E | 개념(Concept)-전략(Strategy)-집행(Execution) 인지 모델 |
| W_총점 | 6개 Working Memory 가중치(W1~W6)의 합산 점수 (0~9.5) |
| W 레벨 | W_총점을 0.5 단위로 구간화한 난이도 레벨 (1~23) |
| C 레벨 | 15개 교과과정 단원 분류 (C1: 한자리 덧셈 ~ C15: 두자리-두자리 받아내림) |
| L-level | 아동의 진단/역량 수준 (L0~L5) |
| Probe | 변인 통제를 위한 확인용 문제 (감별 진단) |
| error_tag | 85개 오답 원인 분류 태그 |
| strategy_tag | 문제가 요구하는 최적 전략 (6종, 정적) |
| observation_tag | 아동의 실제 풀이 행동 (15종, 동적) |
| RT | Response Time, 반응 시간 (밀리초 단위) |
| DTx | Digital Therapeutics, 디지털 치료기기 |
| MECE | Mutually Exclusive, Collectively Exhaustive (상호배타적, 전체포괄적) |
| 경로 A | W 하향 -- 작업기억 부하 경감 (전략은 알지만 실행에서 막힘) |
| 경로 B | C 하향 -- 개념적 후퇴 (기본 개념 자체 결손) |

---

*이 문서는 5개 에이전트(biz, marketing, research, tech, pm)의 분석 결과와 9개 증거 소스(W/C 이중 태그 문제 뱅크 및 적응형 알고리즘 포함)를 통합하여 synth 에이전트가 생성하였습니다.*
