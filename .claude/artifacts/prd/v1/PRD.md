# Maththera PRD v1

**Version**: 1.0
**Date Created**: 2026-02-12
**Language**: 한국어
**Status**: Draft (에이전트 팀 자동 생성)

---

## 1. 개요 (Executive Summary)

Maththera는 **난산증(Dyscalculia) 아동**을 위한 AI 기반 수학 인지 훈련 시스템이다. 뇌과학 기반 **C-S-E(개념-전략-집행) 인지 모델**로 오답의 근본 원인을 진단하고, 개인화된 훈련 모듈을 자동으로 처방한다.

**핵심 파이프라인**: 13,981개 문제 → 85개 오답 원인(7대 인지 카테고리) → 30+2개 훈련 모듈

기존 수학 학습 앱이 정오답만 판별하는 것과 달리, Maththera는 **'왜 틀렸는가'**를 인지 수준에서 분석하고 **전략 전환**을 유도하는 체계적 개입을 제공한다.

---

## 2. 문제 정의

### 핵심 문제

난산증은 지능과 교육 기회가 충분함에도 불구하고, 수적 정보를 처리하는 뇌 회로의 발달적 결함으로 인해 수학 학습에 심각한 어려움을 겪는 상태이다. 이는 **후두정엽(수 표상)과 전전두엽(집행 제어) 사이의 신경학적 연결성 문제**이다.

### 문제의 규모

- 전 세계 학령기 아동의 **3~6%**가 난산증의 영향을 받음
- 난독증(Dyslexia), ADHD와 유사한 유병률이나, **인지도와 개입 도구는 현저히 부족**
- 한국에서 난산증이라는 용어 자체가 생소한 학부모가 대다수

### 현재 상황

- 기존 수학 앱(토도수학, 매쓰홈 등)은 적응형 학습을 제공하나, **인지 원인 진단 기능 부재**
- 해외 제품(Dybuster Calcularis 등)도 85개 오답원인 MECE 분류 수준의 정밀 진단은 부재
- 디지털치료기기(DTx) 시장에서 난산증 특화 제품 공백

---

## 3. 가설

**핵심 가설**: 수감각이 해결되면 수학능력을 향상시킬 수 있으며 난산증은 개선 가능하다.

**부가 가설**:
1. C-S-E 3축 인지 모델로 오답 원인을 정밀 분류하면, 개인화된 훈련 경로 설계가 가능하다.
2. Rule-based 트리거 룰이 AI의 자의적 해석을 배제하여, 진단 일관성을 확보할 수 있다.
3. 정답 여부뿐 아니라 전략 수준(전부 세기 → 10 만들기)의 전환을 유도하면, 장기적 수학 역량이 향상된다.

---

## 4. 목표 / 비목표

### 목표 (In-Scope)

| # | 목표 | 우선순위 |
|---|------|---------|
| 1 | C-S-E 인지 모델 기반 오답 진단 엔진 구현 | P0 |
| 2 | 한자리수 덧셈/뺄셈 문제 출제 및 진단 | P0 |
| 3 | 트리거 룰 기반 개념 태그(C1~C6) 활성화 엔진 | P0 |
| 4 | 85개 오답원인 → 30개 훈련 모듈 자동 매핑 | P0 |
| 5 | 아동 친화적 피드백 (보이스 톤 가이드 준수) | P0 |
| 6 | RT(반응 시간) 측정 및 전략 불일치 감지 | P1 |
| 7 | 제한적 Probe 문제 (공간지각 vs 절차수행 감별) | P1 |
| 8 | 핵심 훈련 모듈 10개 우선 구현 | P1 |
| 9 | 충동적 반응(ATTENTION) 감지 및 개입 | P1 |
| 10 | 학부모/교사 대상 진단 리포트 | P2 |

### 비목표 (Out-of-Scope for MVP)

- 곱셈, 나눗셈, 분수, 소수 연산
- 디지털치료기기(DTx) 인허가
- Cogassist Agent의 완전 자율 매핑 (Phase 2)
- C7 등가성 태그 (보류)
- 오프라인 동작 모드
- 다국어/글로벌 로컬라이제이션

---

## 5. 대상 사용자 / 페르소나

### Primary: 난산증 아동 (6~10세)

- 수감각이 약하여 기본 연산에 어려움을 겪는 초등 저학년
- 작업기억 부하 임계치가 낮아 복잡한 문제에서 쉽게 포기
- 수학 불안(Math Anxiety)이 높아 틀리는 것에 대한 두려움이 큼

### Secondary: 학부모

- 아이의 수학 문제 원인을 모르는 학부모
- "왜 이걸 못 하지?"에 대한 답을 원함
- '혼내지 않는 AI'에 대한 감성적 니즈

### Tertiary: 특수교사/치료사

- 난산증 아동의 인지 수준을 정밀 진단하고 싶은 전문가
- C-S-E 진단 리포트를 통한 체계적 개입 설계 필요
- B2B SaaS 모델의 핵심 고객

---

## 6. 기능 요구사항

### FR-001. C-S-E 진단 엔진

- 개념(C1~C6), 전략(S1~S7), 집행(E1~E3) 축으로 오답 원인 분류
- 문제 유형별 트리거 룰에 따라 개념 태그 활성화
  - 한자리수+한자리수: A/B 유형별 C1~C6 선택적 활성화
  - 한자리수-한자리수: C4 비활성화, C6 항상 활성화
  - 두자리수 연산: C4 항상 활성화
- **Bottom-up Selection**: 기초 문항은 하위 개념 태그(C1, C2)만 스캔하여 과진단 방지

### FR-002. 오답 진단 파이프라인

- Rule-based 엔진 70~90% + AI 보조 10~30% 하이브리드 구조
- 6종 전략 태그(고정)와 15종 관찰 태그(동적) 분리 운영
- 전략 불일치 감지: 문제 요구 전략 vs 아동 실제 전략 비교
  - 예: STR_MAKE10 요구 문제에서 OBS_OVERRELIANCE_COUNTING 관찰 시 진단

### FR-003. 적응형 문제 출제

- L-level(아동 역량 L0~L5) × C-level(문항 복잡도 C1~C5) 2축 난이도 체계
- 15,050개 문제 뱅크에서 아동 수준에 맞는 문제 샘플링
- 6개 가중치(W1~W6)로 레벨 판정: W1 연산, W2 자릿수, W3 숫자크기, W4 복잡성, W5 특수수, W6 표현

### FR-004. 훈련 모듈 자동 매핑

- 85개 오답원인 → 30+2개 훈련 모듈 1:1 매핑
- 훈련 유형 5가지: Perception(지각), Concept(개념), Strategy(전략), Drill(자동화), Intervention(긴급 개입)
- 훈련 모듈별 완료 기준(pass_criterion): 정답률 또는 RT 기반 통과 조건
- MVP Phase 1 핵심 훈련 모듈: T12(10짝찾기), T17(10만들어더하기), T26(자릿값이해), T27(받아올림개념), T30(주의력환기), T04, T08, T11, T15, T22, T24, T06

### FR-005. RT(반응 시간) 측정 및 분석

- 밀리초 단위 클라이언트 사이드 측정 (performance.now())
- RT < 1초 + 오답 = 충동적 반응(ATTENTION_L0_IMPULSE) 감지
- z-score 기반 평가를 위한 기준 데이터 축적 (파일럿에서 수집)

### FR-006. Probe 문제 (제한적)

- 오답 원인 중복 시 변인 통제 확인 문제 출제
- MVP에서는 공간지각 vs 절차수행 감별 시나리오 1개만 구현
- 3문제당 최대 1회 Probe 삽입, 게이미피케이션으로 자연스럽게 제시

### FR-007. AI 피드백 시스템

- 보이스 톤 가이드 준수:
  - 반말, 부드러운 톤, 3문장 이내, 문장당 10자 이내
  - 비난/재촉/비교 금지, 힌트 1개만 제공
- 상황별 4가지 템플릿 풀: 정답 / 오답 / 실수 / 무응답
- MVP에서는 LLM 생성 배제, 템플릿 기반 운영
- 금지어 하드코딩 필터 적용

---

## 7. 비기능 요구사항

### 성능
- 문제 출제 응답 시간: < 200ms
- RT 측정 정밀도: ±10ms 이내
- 진단 엔진 처리 시간: < 500ms

### 보안 및 개인정보
- 아동 사용자 대상 COPPA/PIPA 준수
- 아동 식별자는 익명 UUID로 관리
- RT/응답 데이터 암호화 저장
- 학부모 동의 플로우 필수 탑재

### 접근성
- 난산증 아동의 인지적 특성(작업기억 부하 임계치가 낮음) 고려
- UI 자극 최소화, 단계별 정보 제시
- 기찻길 메타포 기반 시각적 학습 체계

### 데이터 무결성
- 7대 카테고리 × 85개 오답원인 × 30개 훈련모듈 매핑의 MECE 정합성 검증 자동화
- 4개 데이터베이스(문제정의, 오답원인, 훈련매핑, 훈련모듈) 간 참조 무결성 CI 테스트

---

## 8. UX 노트

### 아동 경험 설계

| 상황 | 피드백 예시 | 원칙 |
|------|-----------|------|
| 정답 | "좋아!" "정답이야!" "다음 가자!" | 칭찬 + 확인 |
| 오답 | "괜찮아." "하나만 더!" "다시 해볼까?" | 공감 + 힌트 + 재도전 |
| 실수 | "거의 다 왔어!" "자리만 봐!" "한 번 더!" | 칭찬 + 포인트 힌트 |
| 무응답 | "괜찮아." "하나씩 하자." "어느 게 맞아?" | 안심 + 작은 단계 |

### 시각 메타포: 기찻길 6단계

| 단계 | 지표 | 메타포 |
|------|------|--------|
| 1 기초 | C1/S1 | 기찻길과 낱개 블록 |
| 2 비교 | C2/S2 | 기차 길이 비교 |
| 3 기준 | C3/S3 | 5번 중간역과 색상 변화 |
| 4 단위 | C4/S4 | 황금 기차 변신 (10개 묶음) |
| 5 연산 | C5/S5 | 5-10 채우기 작전 |
| 6 검토 | C6/S6 | 기차 후진 |

---

## 9. 기술 노트

### 아키텍처 개요

```
[클라이언트] ──── [API Gateway] ──── [진단 엔진] ──── [문제 뱅크 DB]
     │                                    │
     │                              [룰 엔진]
     │                              (70~90%)
     │                                    │
     ├── RT 측정 (로컬)              [AI 보조]
     │                              (10~30%)
     │                                    │
     └── 피드백 렌더링            [훈련 매핑 DB]
                                         │
                                   [훈련 모듈]
```

### 주요 기술 의사결정

| 결정 사항 | 선택 | 근거 |
|----------|------|------|
| 진단 엔진 | 결정론적 룰 엔진 우선 | 트리거 룰의 자의적 해석 배제 요구 |
| AI 활용 | 2차 분석에만 제한적 활용 | MVP 진단 일관성 확보 |
| 피드백 생성 | 템플릿 기반 (LLM 배제) | 보이스 톤 가이드 일관성 리스크 방지 |
| RT 측정 | 클라이언트 사이드 | 네트워크 지연 배제 필요 |
| Probe 로직 | 상태 머신(FSM) | 오답→가설→Probe→확정 4단계 전이 |
| 태그 체계 | 계층형 (C5→C5a/C5b 확장 대비) | MECE 강화 및 하위 호환성 |
| 충동 감지 | 클라이언트 경량 룰 평가기 | 서버 왕복 없이 즉시 T30 트리거 |

### 데이터 모델

```
problem_bank (13,981)
├── category, difficulty, complexity
├── strategy_tag (6종, 정적)
├── concept_tags (C1~C6, 문제 유형별 활성화)
└── level_tag (L1~L5)

session_response (동적)
├── user_id (UUID)
├── problem_id
├── answer, is_correct
├── rt_ms
├── observation_tag (15종)
└── error_tag (85개 중 매칭)

training_mapping (85)
├── error_tag_id
└── training_module_id

training_module (30+2)
├── type (perception/concept/strategy/drill/intervention)
├── pass_criterion
└── fallback_module_id
```

---

## 10. GTM 전략

### 포지셔닝

**이중 메시징 전략**:
- **B2B (전문가 채널)**: "난산증 전용 인지 훈련 프로그램" — 전문성 강조
- **B2C (학부모 채널)**: "수감각이 약한 아이를 위한 AI 수학 훈련" — 접근성 강조

### 차별화 포인트

1. **인지 원인 진단**: 정오답이 아닌 '왜 틀렸는가'를 분석
2. **전략 전환 유도**: 단순 반복이 아닌 인지 전략 업그레이드
3. **과학적 체계**: C-S-E 인지 모델, 85개 오답원인 MECE 분류
4. **감별 진단**: Probe 문제로 변인 통제 기반 원인 규명
5. **아동 친화적 톤**: "혼내지 않는 AI"

### 타겟 채널

| 채널 | 대상 | 전략 |
|------|------|------|
| B2B (1차) | 특수교육센터, 치료실 | KOL 네트워크, 학술 컨퍼런스 |
| B2C (병행) | 학부모 | 체험판, 콘텐츠 마케팅 |
| 학술 | 연구자, 임상가 | 파일럿 결과 논문화 |

### 런칭 단계

1. **Alpha**: 내부 QA + 전문가 리뷰 (4주)
2. **파일럿 Phase 1**: 소규모(n=20~30) 사용성 테스트 (6주)
3. **파일럿 Phase 2**: 확대(n=50~100) RT baseline 수집 (8주)
4. **Beta**: 제한 공개 (8주)
5. **GA(General Availability)**: 정식 출시

### 용어 가이드라인

- ✅ 사용: '훈련', '분석', '지원', '인지 훈련 프로그램'
- ❌ 금지: '치료', '진단' (의료법 위반 소지)

---

## 11. 성공 지표

### Primary KPI

| 지표 | 목표 | 측정 방법 |
|------|------|----------|
| 전략 전환율 | 파일럿 대상 40%+ | 동일 문제 유형에서 상위 전략 사용 비율 |
| 진단-전문가 일치도 | 80%+ | AI 진단 vs 임상가 코딩 일치도 (Inter-rater reliability) |
| 재시도율 | 오답 후 70%+ | 오답 발생 후 자발적 재도전 비율 |

### Secondary KPI

| 지표 | 목표 |
|------|------|
| 세션 완료율 | 85%+ |
| 파일럿 참여자 만족도 (NPS) | 50+ |
| RT 개선율 | 동일 레벨 문제 RT 20%+ 감소 |

---

## 12. 리스크

| # | 리스크 | 영향 | 완화 전략 |
|---|--------|------|----------|
| 1 | RT baseline 데이터 부재로 오진 위험 | High | 2단계 파일럿(20→100명)으로 연령별 기준 RT 실측 |
| 2 | AI 비결정론적 특성으로 진단 일관성 저하 | High | 룰 엔진 우선, AI는 2차 분석에만 활용 |
| 3 | '치료' 표현의 의료법 위반 소지 | High | '인지 훈련 프로그램'으로 포지셔닝, 용어 가이드라인 |
| 4 | 난산증 인지도 부족으로 시장 교육 비용 과다 | High | '수감각이 약한 아이'로 1차 진입, 인식 캠페인 병행 |
| 5 | 아동 개인정보보호 규정 미준수 | High | COPPA/PIPA 준수, 익명 UUID, 학부모 동의 필수 |
| 6 | AI 피드백이 톤 가이드 위반 시 심리적 부정 경험 | High | 템플릿 기반, 금지어 필터 하드코딩 |
| 7 | 트리거 룰 경계 조건에서 과잉/미진단 | Medium | 문제 유형별 태그 스캔 범위 명시적 제한 |
| 8 | 85개 원인→30개 모듈 수렴 시 교정 효과 희석 | Medium | 동일 모듈 내 파라미터 동적 조절 |
| 9 | Probe 빈번 삽입으로 학습 몰입 저해 | Medium | 3문제당 최대 1회, 게이미피케이션 포장 |
| 10 | Level 1 문제 81개(0.5%)로 초기 진단 정밀도 저하 | Medium | Level 1 문제 풀 확장 또는 CAT 방식 초기 레벨 판정 |
| 11 | 곱셈/나눗셈 확장 시 매트릭스 재설계 필요 | Medium | 모듈형 아키텍처, 연산 유형 독립 확장 가능 설계 |

---

## 13. 마일스톤

### MVP Phase 1 (12주)

| 주차 | 목표 | 산출물 |
|------|------|--------|
| W1~W2 | 데이터 모델 설계, 문제 뱅크 구축 | DB 스키마, 한자리수 문제 임포트 |
| W3~W4 | 룰 엔진 핵심 구현 | 트리거 룰 엔진, C1~C6 활성화 로직 |
| W5~W6 | 오답 진단 파이프라인 | 85개 오답원인 매핑, 전략/관찰 태그 분리 |
| W7~W8 | 훈련 모듈 10개 구현 | T12, T17, T26, T27, T30 등 핵심 모듈 |
| W9~W10 | 클라이언트 UI + RT 측정 | 아동 UI, 피드백 시스템, RT 측정 |
| W11~W12 | 통합 테스트 + Alpha | QA, 전문가 리뷰, 매핑 무결성 검증 |

### MVP Phase 2 (8주)

- 두자리수 연산 확장
- C5a/C5b 분리, C1-Zero 서브태그
- Probe 시스템 확장
- 학부모/교사 대시보드
- AI 보조 진단 (제한적 LLM 활용)

### Phase 3 (계획)

- Cogassist Agent 자율 매핑
- DTx 인허가 검토
- 글로벌 로컬라이제이션
- 곱셈/나눗셈 확장

---

## 14. 미해결 질문

### High Priority

| # | 질문 | 담당 |
|---|------|------|
| 1 | RT z-score 산출을 위한 연령별/레벨별 기준 분포 데이터를 어디서 확보할 것인가? | Data Science |
| 2 | C5a(합성)과 C5b(분해)의 분리가 실제 진단 정확도를 유의미하게 향상시키는가? | Research |
| 3 | AI/LLM 의존 범위 — 트리거 룰만으로 해결되지 않는 '복합 오답 패턴'의 비율은? | Tech |
| 4 | Probe 기반 변인 통제 진단의 실시간 적용이 아동의 학습 흐름을 방해하지 않는가? | UX/Research |
| 5 | 85개 오답 원인에서 30개 훈련 모듈로의 다대일 매핑에서 교정 효과가 희석되지 않는가? | Research |
| 6 | 15,050개 문제와 13,981개 문제정의 간의 수량 차이(1,069개) 정합성 확인 | Domain Expert |

### Medium Priority

| # | 질문 |
|---|------|
| 7 | C7 등가성 태그가 필요한 문제 유형의 범위와 난산증 아동 발생 빈도 |
| 8 | 뺄셈 문제 유형의 전략 태그(S1~S7) 매핑이 덧셈과 동일한 구조로 적용 가능한가? |
| 9 | 오프라인 환경(학교, 치료실) 지원 필요 여부 |
| 10 | 학부모/교사 대시보드 MVP 범위: 진단 리포트만 vs 훈련 이력 추적 포함 |
| 11 | B2B vs B2C 채널별 CAC과 LTV 비교 분석 |
| 12 | 글로벌 시장 확장 시 로컬라이제이션 범위와 비용 산정 |

---

## 부록: 충돌 해결 요약

이 PRD 생성 과정에서 6개 에이전트 간 7건의 충돌이 식별되고 해결되었다. 상세 내용은 `conflicts.json` 참조.

| # | 주제 | 관련 역할 | 해결 |
|---|------|----------|------|
| 1 | DTx vs 에듀테크 포지셔닝 | biz, marketing | 에듀테크 우선, DTx는 Phase 2 |
| 2 | B2B vs B2C 우선순위 | biz, marketing | B2B2C 하이브리드, B2B 1차 |
| 3 | AI/LLM 활용 범위 | tech, biz | 룰 엔진 우선, AI는 2차 분석 |
| 4 | 파일럿 규모 (20 vs 50 vs 100명) | biz, pm, tech | 2단계 (20→100명) |
| 5 | MVP 연산 범위 | pm, biz | Phase 1은 한자리수만 |
| 6 | 난산증 전용 vs 수학 기초 역량 | marketing, biz | 이중 메시징 전략 |
| 7 | Probe의 MVP 포함 여부 | pm, research | 제한적 포함 (1개 시나리오) |

---

*이 PRD는 6역할 에이전트 팀(biz, marketing, research, tech, pm, synth)에 의해 자동 생성되었습니다.*
*증거 기반: 7개 Google Drive 문서, 55개 청크, citations.json 참조*
